{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Face Super-Resolution with UNet\n",
        "## Goal: Enhance 64x64 face images to 256x256 using UNet\n",
        "\n",
        "Based on: https://www.kaggle.com/code/ashishjangra27/face-resolution-enhancement-with-unet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install -q numpy pillow matplotlib opencv-python scikit-image tensorflow==2.19.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from skimage import io, transform\n",
        "\n",
        "# Check GPU availability\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Define UNet Architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def conv_block(x, filters, kernel_size=3, strides=1, padding='same'):\n",
        "    \"\"\"Convolutional block with BatchNorm and ReLU\"\"\"\n",
        "    x = layers.Conv2D(filters, kernel_size, strides=strides, padding=padding)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def upsample_block(x, filters, kernel_size=3, strides=2, padding='same'):\n",
        "    \"\"\"Upsampling block with Conv2DTranspose\"\"\"\n",
        "    x = layers.Conv2DTranspose(filters, kernel_size, strides=strides, padding=padding)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def build_unet(input_shape=(64, 64, 3)):\n",
        "    \"\"\"Build UNet model for face super-resolution (64x64 -> 256x256)\"\"\"\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    # Encoder (Downsampling)\n",
        "    # Block 1: 64x64 -> 32x32\n",
        "    conv1 = conv_block(inputs, 64)\n",
        "    conv1 = conv_block(conv1, 64)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    # Block 2: 32x32 -> 16x16\n",
        "    conv2 = conv_block(pool1, 128)\n",
        "    conv2 = conv_block(conv2, 128)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    # Block 3: 16x16 -> 8x8\n",
        "    conv3 = conv_block(pool2, 256)\n",
        "    conv3 = conv_block(conv3, 256)\n",
        "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    # Block 4: 8x8 -> 4x4\n",
        "    conv4 = conv_block(pool3, 512)\n",
        "    conv4 = conv_block(conv4, 512)\n",
        "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    # Bottleneck: 4x4\n",
        "    conv5 = conv_block(pool4, 1024)\n",
        "    conv5 = conv_block(conv5, 1024)\n",
        "\n",
        "    # Decoder (Upsampling)\n",
        "    # Block 6: 4x4 -> 8x8\n",
        "    up6 = upsample_block(conv5, 512)\n",
        "    concat6 = layers.Concatenate()([conv4, up6])\n",
        "    conv6 = conv_block(concat6, 512)\n",
        "    conv6 = conv_block(conv6, 512)\n",
        "\n",
        "    # Block 7: 8x8 -> 16x16\n",
        "    up7 = upsample_block(conv6, 256)\n",
        "    concat7 = layers.Concatenate()([conv3, up7])\n",
        "    conv7 = conv_block(concat7, 256)\n",
        "    conv7 = conv_block(conv7, 256)\n",
        "\n",
        "    # Block 8: 16x16 -> 32x32\n",
        "    up8 = upsample_block(conv7, 128)\n",
        "    concat8 = layers.Concatenate()([conv2, up8])\n",
        "    conv8 = conv_block(concat8, 128)\n",
        "    conv8 = conv_block(conv8, 128)\n",
        "\n",
        "    # Block 9: 32x32 -> 64x64\n",
        "    up9 = upsample_block(conv8, 64)\n",
        "    concat9 = layers.Concatenate()([conv1, up9])\n",
        "    conv9 = conv_block(concat9, 64)\n",
        "    conv9 = conv_block(conv9, 64)\n",
        "\n",
        "    # Final upsampling: 64x64 -> 256x256 (4x upsampling)\n",
        "    up10 = upsample_block(conv9, 64, strides=4)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = layers.Conv2D(3, 1, activation='sigmoid', padding='same')(up10)\n",
        "\n",
        "    model = keras.Model(inputs, outputs, name='FaceSuperResolutionUNet')\n",
        "    return model\n",
        "\n",
        "# Build the model\n",
        "model = build_unet()\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='mse',\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "print(\"Model Summary:\")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Image Preprocessing Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_image(image_path, target_size=(64, 64)):\n",
        "    \"\"\"Load and preprocess image for model input\"\"\"\n",
        "    # Load image\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "\n",
        "    # Resize to target size\n",
        "    img_resized = img.resize(target_size, Image.LANCZOS)\n",
        "\n",
        "    # Convert to numpy array and normalize\n",
        "    img_array = np.array(img_resized, dtype=np.float32) / 255.0\n",
        "\n",
        "    # Add batch dimension\n",
        "    img_batch = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    return img_batch, img_resized\n",
        "\n",
        "def postprocess_image(prediction):\n",
        "    \"\"\"Convert model prediction back to image\"\"\"\n",
        "    # Remove batch dimension\n",
        "    img_array = prediction[0]\n",
        "\n",
        "    # Denormalize\n",
        "    img_array = np.clip(img_array * 255.0, 0, 255).astype(np.uint8)\n",
        "\n",
        "    # Convert to PIL Image\n",
        "    img = Image.fromarray(img_array)\n",
        "\n",
        "    return img\n",
        "\n",
        "def create_sample_face_image():\n",
        "    \"\"\"Create a simple synthetic face image for testing\"\"\"\n",
        "    # Create a 64x64 synthetic face-like image\n",
        "    img = np.zeros((64, 64, 3), dtype=np.uint8)\n",
        "\n",
        "    # Face outline (oval)\n",
        "    cv2.ellipse(img, (32, 35), (25, 30), 0, 0, 360, (255, 220, 177), -1)\n",
        "\n",
        "    # Eyes\n",
        "    cv2.circle(img, (25, 25), 3, (0, 0, 0), -1)\n",
        "    cv2.circle(img, (39, 25), 3, (0, 0, 0), -1)\n",
        "\n",
        "    # Nose\n",
        "    cv2.ellipse(img, (32, 35), (2, 4), 0, 0, 360, (200, 180, 150), -1)\n",
        "\n",
        "    # Mouth\n",
        "    cv2.ellipse(img, (32, 45), (6, 3), 0, 0, 180, (200, 100, 100), -1)\n",
        "\n",
        "    return Image.fromarray(img)\n",
        "\n",
        "print(\"Preprocessing functions defined successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Demo with Sample Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a sample face image\n",
        "sample_face = create_sample_face_image()\n",
        "\n",
        "# Save the sample image\n",
        "sample_face.save('sample_face_64x64.png')\n",
        "\n",
        "# Preprocess the image\n",
        "input_batch, input_img = preprocess_image('sample_face_64x64.png')\n",
        "\n",
        "print(f\"Input image shape: {input_batch.shape}\")\n",
        "print(f\"Input image size: {input_img.size}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Apply UNet Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make prediction\n",
        "print(\"Making prediction...\")\n",
        "prediction = model.predict(input_batch, verbose=1)\n",
        "\n",
        "print(f\"Prediction shape: {prediction.shape}\")\n",
        "print(f\"Expected output size: 256x256 pixels\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Postprocess and Display Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert prediction to image\n",
        "enhanced_img = postprocess_image(prediction)\n",
        "\n",
        "# Save enhanced image\n",
        "enhanced_img.save('enhanced_face_256x256.png')\n",
        "\n",
        "# Display comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Original 64x64 image\n",
        "axes[0].imshow(input_img)\n",
        "axes[0].set_title('Original Face (64x64)', fontsize=14)\n",
        "axes[0].axis('off')\n",
        "\n",
        "# Enhanced 256x256 image\n",
        "axes[1].imshow(enhanced_img)\n",
        "axes[1].set_title('Enhanced Face (256x256)', fontsize=14)\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Original image size: {input_img.size}\")\n",
        "print(f\"Enhanced image size: {enhanced_img.size}\")\n",
        "print(\"Images saved as 'sample_face_64x64.png' and 'enhanced_face_256x256.png'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Test with Your Own Image (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment and modify this section to test with your own image\n",
        "#\n",
        "# # Replace 'your_image.jpg' with the path to your image\n",
        "# your_image_path = 'your_image.jpg'\n",
        "#\n",
        "# # Preprocess your image\n",
        "# input_batch, input_img = preprocess_image(your_image_path)\n",
        "#\n",
        "# # Make prediction\n",
        "# prediction = model.predict(input_batch, verbose=1)\n",
        "#\n",
        "# # Convert to image\n",
        "# enhanced_img = postprocess_image(prediction)\n",
        "#\n",
        "# # Display results\n",
        "# fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "# axes[0].imshow(input_img)\n",
        "# axes[0].set_title('Your Original Image (64x64)')\n",
        "# axes[0].axis('off')\n",
        "#\n",
        "# axes[1].imshow(enhanced_img)\n",
        "# axes[1].set_title('Enhanced Image (256x256)')\n",
        "# axes[1].axis('off')\n",
        "#\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "print(\"To test with your own image, uncomment and modify the code above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrates:\n",
        "1. ✅ **UNet Architecture**: Custom UNet for 64x64 → 256x256 face enhancement\n",
        "2. ✅ **Image Preprocessing**: Loading and resizing images to 64x64\n",
        "3. ✅ **Model Application**: Running inference with the UNet model\n",
        "4. ✅ **Output Handling**: Converting predictions to 256x256 images\n",
        "5. ✅ **Visualization**: Side-by-side comparison of original and enhanced images\n",
        "\n",
        "**Next Steps for Production:**\n",
        "- Train the model on a face dataset (e.g., CelebA)\n",
        "- Use pre-trained weights from the Kaggle notebook\n",
        "- Implement data augmentation for better generalization\n",
        "- Add perceptual loss for better visual quality\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
